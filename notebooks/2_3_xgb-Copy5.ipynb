{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "\"\"\"\n",
    "This simple scripts demonstrates the use of xgboost eval results to get the best round\n",
    "for the current fold and accross folds. \n",
    "It also shows an upsampling method that limits cross-validation overfitting.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "from numba import jit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time \n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Original author CPMP : https://www.kaggle.com/cpmpml\n",
    "    In kernel : https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_encode(trn_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.enable()\n",
    "\n",
    "trn_df = pd.read_csv(\"../data/train.csv\", index_col=0)\n",
    "sub_df = pd.read_csv(\"../data/test.csv\", index_col=0)\n",
    "\n",
    "# trn_df = pd.read_csv(\"../data/train.csv\")\n",
    "# sub_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "target = trn_df[\"target\"]\n",
    "del trn_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 57)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "id                                                                      \n",
       "7           2              2          5              1              0   \n",
       "9           1              1          7              0              0   \n",
       "13          5              4          9              1              0   \n",
       "16          0              1          2              0              0   \n",
       "17          0              2          0              1              0   \n",
       "\n",
       "    ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  \\\n",
       "id                                                                              \n",
       "7               0              1              0              0              0   \n",
       "9               0              0              1              0              0   \n",
       "13              0              0              1              0              0   \n",
       "16              1              0              0              0              0   \n",
       "17              1              0              0              0              0   \n",
       "\n",
       "         ...        ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  \\\n",
       "id       ...                                                         \n",
       "7        ...                 9           1           5           8   \n",
       "9        ...                 3           1           1           9   \n",
       "13       ...                 4           2           7           7   \n",
       "16       ...                 2           2           4           9   \n",
       "17       ...                 3           1           1           3   \n",
       "\n",
       "    ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n",
       "id                                                                   \n",
       "7                0               1               1               0   \n",
       "9                0               1               1               0   \n",
       "13               0               1               1               0   \n",
       "16               0               0               0               0   \n",
       "17               0               0               0               1   \n",
       "\n",
       "    ps_calc_19_bin  ps_calc_20_bin  \n",
       "id                                  \n",
       "7                0               1  \n",
       "9                1               0  \n",
       "13               1               0  \n",
       "16               0               0  \n",
       "17               1               0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "    \"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "    \"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "    \"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "    \"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "    \"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "    \"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "    \"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "    \"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "    \"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "    \"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "    \"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "    \"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "    \"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "    \"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "    \"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "    \"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "    \"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "    \"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "    \"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "    \"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "    \"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "    \"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "    \"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "    \"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "    \"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "    \"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "    \"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "    \"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "    \"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "    \"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "    \"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "    \"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "    \"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "    \"ps_car_11_cat\" # Very nice spot from Tilii : https://www.kaggle.com/tilii7\n",
    "]\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ps_car_12 = cc,\n",
    "# ps_car_13 = vehicle value,\n",
    "# ps_car_14 = vehicle weight Kg\n",
    "# ps_car_15 = manufacture year\n",
    "# ps_car_06_cat = Car Makers\n",
    "\n",
    "# ps_car_11_cat = Individual Car Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ps_reg_03                          :     0.1284\n",
    "# ps_car_13                          :     0.1179\n",
    "# ps_car_14                          :     0.0718\n",
    "# ps_ind_03                          :     0.0594\n",
    "# ps_ind_15                          :     0.0441\n",
    "# ps_ind_01                          :     0.0345\n",
    "# ps_car_11_cat_avg                  :     0.0340\n",
    "# ps_reg_02                          :     0.0300\n",
    "# ps_reg_01_plus_ps_car_04_cat_avg   :     0.0281\n",
    "# ps_car_15                          :     0.0270\n",
    "# ps_car_11_cat                      :     0.0265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    d_median = df.median(axis=0)\n",
    "    d_mean = df.mean(axis=0)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "#     df['ps_car_13_d_ps_reg_03'] = df['ps_car_13'] / df['ps_reg_03']\n",
    "#     df['ps_car_13_od_ps_reg_03'] = df['ps_reg_03'] / df['ps_car_13']\n",
    "#     df['ps_car_13_plus_ps_reg_03'] = df['ps_car_13'] + df['ps_reg_03']\n",
    "#     df['ps_car_13_ps_sub_reg_03'] = df['ps_car_13'] - df['ps_reg_03']\n",
    "#     df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c: #standard arithmetic\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "            #df[c+str('_sq')] = np.power(df[c].values,2).astype(np.float32)\n",
    "            #df[c+str('_sqr')] = np.square(df[c].values).astype(np.float32)\n",
    "            #df[c+str('_log')] = np.log(np.abs(df[c].values) + 1)\n",
    "            #df[c+str('_exp')] = np.exp(df[c].values) - 1\n",
    "        train_features.append(c+str('_median_range'))\n",
    "        train_features.append(c+str('_mean_range'))\n",
    "    train_features.append('ps_car_13_x_ps_reg_03')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_df=transform_df(trn_df)\n",
    "sub_df=transform_df(sub_df)\n",
    "\n",
    "# train_features.append('ps_car_13_x_ps_reg_03')\n",
    "# train_features.append('ps_car_13_d_ps_reg_03')\n",
    "# train_features.append('ps_car_13_od_ps_reg_03')\n",
    "# train_features.append('ps_car_13_plus_ps_reg_03')\n",
    "# train_features.append('ps_car_13_ps_sub_reg_03')\n",
    "# train_features.append('negative_one_vals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f_ind_reg = [\n",
    "#     'ps_car_13',\n",
    "#     'ps_reg_03',\n",
    "#     'ps_ind_03',\n",
    "#     'ps_car_14'\n",
    "# ]\n",
    "\n",
    "f_ind_reg = [\n",
    "    'ps_car_13',\n",
    "    'ps_reg_03'\n",
    "]\n",
    "\n",
    "# transformations = ['sq', 'sqrt', 'exp', 'div_sqrt', 'cbrt', 'pow_3', 'pow_5', 'sin', 'log']\n",
    "transformations = ['sin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans(t, x):\n",
    "    if (x == -1) | (float(x) == -1.0):\n",
    "        return -1\n",
    "    if float(x) == 0.0:\n",
    "        x = float(x) + 0.001 # increment x by delta\n",
    "    if t == 'sq':\n",
    "        return x * x\n",
    "    elif t == 'sqrt':\n",
    "        return math.sqrt(x)\n",
    "    elif t == 'exp':\n",
    "        return math.exp(x)\n",
    "    elif t == 'div_sqrt':\n",
    "        return 1./math.sqrt(x)\n",
    "    elif t == 'cbrt':\n",
    "        return x ** (1./3)\n",
    "    elif t == 'pow_3':\n",
    "        return 3 ** x\n",
    "    elif t == 'pow_5':\n",
    "        return 5 ** x\n",
    "    elif t == 'pow_5':\n",
    "        return 5 ** x\n",
    "    elif t == 'sin':\n",
    "        return math.sin(x)\n",
    "    elif t == 'log':\n",
    "        return math.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # transforms\n",
    "# for i in tqdm(range(len(f_ind_reg))):\n",
    "#     col = f_ind_reg[i]\n",
    "#     for t in transformations:\n",
    "#         new_col = col + '_t_' + str(t)\n",
    "# #         print(new_col)\n",
    "#         trn_df[new_col] = trn_df[col].map(lambda x: trans(t,x))\n",
    "#         sub_df[new_col] = sub_df[col].map(lambda x: trans(t,x))\n",
    "        \n",
    "#         train_features.append(new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.1"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    trn_df[name1] = trn_df[f1].apply(lambda x: str(x)) + \"_\" + trn_df[f2].apply(lambda x: str(x))\n",
    "    sub_df[name1] = sub_df[f1].apply(lambda x: str(x)) + \"_\" + sub_df[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(trn_df[name1].values) + list(sub_df[name1].values))\n",
    "    trn_df[name1] = lbl.transform(list(trn_df[name1].values))\n",
    "    sub_df[name1] = lbl.transform(list(sub_df[name1].values))\n",
    "\n",
    "    train_features.append(name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f_calc_counts = ['ps_reg_03','ps_car_13']\n",
    "# f_calc_counts = ['ps_car_12','ps_car_13','ps_car_14','ps_car_15', 'ps_reg_03']\n",
    "f_calc_counts = ['ps_car_14','ps_car_13','ps_reg_03', 'ps_ind_03']\n",
    "# f_calc_counts = ['ps_car_13']\n",
    "# f_calc_counts = [\n",
    "# 'ps_calc_10',    #       :  309.57 / shadow  296.18\n",
    "# 'ps_calc_01',    #       :  205.10 / shadow  189.43\n",
    "# 'ps_calc_02',    #       :  201.08 / shadow  192.53\n",
    "# 'ps_calc_03',    #       :  190.70 / shadow  188.47\n",
    "# 'ps_calc_13',    #       :  188.75 / shadow  181.13\n",
    "# 'ps_calc_08',    #       :  172.73 / shadow  169.42\n",
    "# 'ps_calc_07',    #       :  170.48 / shadow  162.17\n",
    "# 'ps_calc_12',    #       :  135.05 / shadow  133.40\n",
    "# 'ps_calc_04'\n",
    "# ]\n",
    "# f_calc_cats = ['ps_ind_05_cat']\n",
    "f_calc_cats = ['ps_car_01_cat', 'ps_reg_01_plus_ps_car_04_cat']\n",
    "# f_calc_cats = ['ps_car_11_cat', 'ps_car_06_cat', 'ps_reg_01_plus_ps_car_04_cat']\n",
    "# f_calc_cats = ['ps_car_01_cat', 'ps_ind_05_cat']\n",
    "\n",
    "# ps_reg_03                          :     0.1117\n",
    "# ps_car_13                          :     0.1115\n",
    "# ps_car_14                          :     0.0619\n",
    "# ps_ind_03                          :     0.0569\n",
    "# ps_ind_15                          :     0.0423\n",
    "# ps_ind_01                          :     0.0334\n",
    "# ps_car_11_cat_avg                  :     0.0313\n",
    "# ps_reg_02                          :     0.0300\n",
    "# ps_reg_01_plus_ps_car_04_cat_avg   :     0.0291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in f_calc_counts:\n",
    "    for f in f_calc_cats:\n",
    "\n",
    "        new_col1 = '{}_{}_mean'.format(col, f) \n",
    "        new_col2 = '{}_{}_median'.format(col, f) \n",
    "        new_col3 = '{}_{}_skew'.format(col, f) \n",
    "        new_col4 = '{}_{}_kurtosis'.format(col, f) \n",
    "        trn_df[new_col1] = 0\n",
    "        trn_df[new_col2] = 0\n",
    "        trn_df[new_col3] = 0\n",
    "        trn_df[new_col4] = 0\n",
    "        \n",
    "        sub_df[new_col1] = 0\n",
    "        sub_df[new_col2] = 0\n",
    "        sub_df[new_col3] = 0\n",
    "        sub_df[new_col4] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 4/4 [10:26<00:00, 156.42s/it]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(f_calc_counts):\n",
    "    for f in f_calc_cats:\n",
    "        new_col1 = '{}_{}_mean'.format(col, f) \n",
    "        new_col2 = '{}_{}_median'.format(col, f) \n",
    "        new_col3 = '{}_{}_skew'.format(col, f) \n",
    "        new_col4 = '{}_{}_kurtosis'.format(col, f) \n",
    "        unique_f = np.unique(trn_df[f].values)\n",
    "        for val in unique_f:\n",
    "            if val == -1:\n",
    "                continue\n",
    "            data1 = trn_df[col][trn_df[f] == val]\n",
    "            mean1 = data1.mean()\n",
    "            median1 = data1.median()\n",
    "            skew1 = data1.skew()\n",
    "            kurtosis1 = data1.kurtosis()\n",
    "            trn_df[new_col1][trn_df[f] == val] = mean1\n",
    "            trn_df[new_col2][trn_df[f] == val] = median1\n",
    "            trn_df[new_col3][trn_df[f] == val] = skew1\n",
    "            trn_df[new_col4][trn_df[f] == val] = kurtosis1\n",
    "            \n",
    "            data1 = sub_df[col][sub_df[f] == val]\n",
    "            mean1 = data1.mean()\n",
    "            median1 = data1.median()\n",
    "            skew1 = data1.skew()\n",
    "            kurtosis1 = data1.kurtosis()\n",
    "            sub_df[new_col1][sub_df[f] == val] = mean1\n",
    "            sub_df[new_col2][sub_df[f] == val] = median1\n",
    "            sub_df[new_col3][sub_df[f] == val] = skew1\n",
    "            sub_df[new_col4][sub_df[f] == val] = kurtosis1\n",
    "            \n",
    "            data2 = trn_df[col][trn_df[f] == val]\n",
    "            mean2 = data2.mean()\n",
    "            median2 = data2.median()\n",
    "            skew2 = data2.skew()\n",
    "            kurtosis2 = data1.kurtosis()\n",
    "            trn_df[new_col1][trn_df[f] == val] = mean2\n",
    "            trn_df[new_col2][trn_df[f] == val] = median2\n",
    "            trn_df[new_col3][trn_df[f] == val] = skew2\n",
    "            trn_df[new_col4][trn_df[f] == val] = kurtosis2\n",
    "            \n",
    "            data2 = sub_df[col][sub_df[f] == val]\n",
    "            mean2 = data2.mean()\n",
    "            median2 = data2.median()\n",
    "            skew2 = data2.skew()\n",
    "            kurtosis2 = data1.kurtosis()\n",
    "            sub_df[new_col1][sub_df[f] == val] = mean2\n",
    "            sub_df[new_col2][sub_df[f] == val] = median2\n",
    "            sub_df[new_col3][sub_df[f] == val] = skew2\n",
    "            sub_df[new_col4][sub_df[f] == val] = kurtosis2\n",
    "        \n",
    "        train_features.append(new_col1)\n",
    "        train_features.append(new_col2)\n",
    "        train_features.append(new_col3)\n",
    "        train_features.append(new_col4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Suspicious features (11)\n",
    "f_calc_cols = [\n",
    "'ps_calc_10',    #       :  309.57 / shadow  296.18\n",
    "'ps_calc_01',    #       :  205.10 / shadow  189.43\n",
    "'ps_calc_02',    #       :  201.08 / shadow  192.53\n",
    "'ps_calc_03',    #       :  190.70 / shadow  188.47\n",
    "'ps_calc_13',    #       :  188.75 / shadow  181.13\n",
    "'ps_calc_08',    #       :  172.73 / shadow  169.42\n",
    "'ps_calc_07',    #       :  170.48 / shadow  162.17\n",
    "'ps_calc_12',    #       :  135.05 / shadow  133.40\n",
    "'ps_calc_04'\n",
    "]\n",
    "#       :  130.43 / shadow  126.17\n",
    "# ps_calc_17_bin #      :   40.23 / shadow   37.10\n",
    "# ps_car_10_cat   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f_calc_counts = ['ps_reg_03','ps_car_13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ps_ind_06_bin_median_range' 'ps_ind_06_bin_mean_range'\\n 'ps_ind_07_bin_median_range' 'ps_ind_07_bin_mean_range'\\n 'ps_ind_08_bin_median_range' 'ps_ind_08_bin_mean_range'\\n 'ps_ind_09_bin_median_range' 'ps_ind_09_bin_mean_range'\\n 'ps_ind_10_bin_median_range' 'ps_ind_10_bin_mean_range'\\n 'ps_ind_11_bin_median_range' 'ps_ind_11_bin_mean_range'\\n 'ps_ind_12_bin_median_range' 'ps_ind_12_bin_mean_range'\\n 'ps_ind_13_bin_median_range' 'ps_ind_13_bin_mean_range'\\n 'ps_ind_16_bin_median_range' 'ps_ind_16_bin_mean_range'\\n 'ps_ind_17_bin_median_range' 'ps_ind_17_bin_mean_range'\\n 'ps_ind_18_bin_median_range' 'ps_ind_18_bin_mean_range'\\n 'ps_calc_15_bin_median_range' 'ps_calc_15_bin_mean_range'\\n 'ps_calc_16_bin_median_range' 'ps_calc_16_bin_mean_range'\\n 'ps_calc_17_bin_median_range' 'ps_calc_17_bin_mean_range'\\n 'ps_calc_18_bin_median_range' 'ps_calc_18_bin_mean_range'\\n 'ps_calc_19_bin_median_range' 'ps_calc_19_bin_mean_range'\\n 'ps_calc_20_bin_median_range' 'ps_calc_20_bin_mean_range'\\n 'ps_ind_06_bin_median_range' 'ps_ind_06_bin_mean_range'\\n 'ps_ind_07_bin_median_range' 'ps_ind_07_bin_mean_range'\\n 'ps_ind_08_bin_median_range' 'ps_ind_08_bin_mean_range'\\n 'ps_ind_09_bin_median_range' 'ps_ind_09_bin_mean_range'\\n 'ps_ind_10_bin_median_range' 'ps_ind_10_bin_mean_range'\\n 'ps_ind_11_bin_median_range' 'ps_ind_11_bin_mean_range'\\n 'ps_ind_12_bin_median_range' 'ps_ind_12_bin_mean_range'\\n 'ps_ind_13_bin_median_range' 'ps_ind_13_bin_mean_range'\\n 'ps_ind_16_bin_median_range' 'ps_ind_16_bin_mean_range'\\n 'ps_ind_17_bin_median_range' 'ps_ind_17_bin_mean_range'\\n 'ps_ind_18_bin_median_range' 'ps_ind_18_bin_mean_range'\\n 'ps_calc_15_bin_median_range' 'ps_calc_15_bin_mean_range'\\n 'ps_calc_16_bin_median_range' 'ps_calc_16_bin_mean_range'\\n 'ps_calc_17_bin_median_range' 'ps_calc_17_bin_mean_range'\\n 'ps_calc_18_bin_median_range' 'ps_calc_18_bin_mean_range'\\n 'ps_calc_19_bin_median_range' 'ps_calc_19_bin_mean_range'\\n 'ps_calc_20_bin_median_range' 'ps_calc_20_bin_mean_range'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-947f3fdbd78d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrn_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msub_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['ps_ind_06_bin_median_range' 'ps_ind_06_bin_mean_range'\\n 'ps_ind_07_bin_median_range' 'ps_ind_07_bin_mean_range'\\n 'ps_ind_08_bin_median_range' 'ps_ind_08_bin_mean_range'\\n 'ps_ind_09_bin_median_range' 'ps_ind_09_bin_mean_range'\\n 'ps_ind_10_bin_median_range' 'ps_ind_10_bin_mean_range'\\n 'ps_ind_11_bin_median_range' 'ps_ind_11_bin_mean_range'\\n 'ps_ind_12_bin_median_range' 'ps_ind_12_bin_mean_range'\\n 'ps_ind_13_bin_median_range' 'ps_ind_13_bin_mean_range'\\n 'ps_ind_16_bin_median_range' 'ps_ind_16_bin_mean_range'\\n 'ps_ind_17_bin_median_range' 'ps_ind_17_bin_mean_range'\\n 'ps_ind_18_bin_median_range' 'ps_ind_18_bin_mean_range'\\n 'ps_calc_15_bin_median_range' 'ps_calc_15_bin_mean_range'\\n 'ps_calc_16_bin_median_range' 'ps_calc_16_bin_mean_range'\\n 'ps_calc_17_bin_median_range' 'ps_calc_17_bin_mean_range'\\n 'ps_calc_18_bin_median_range' 'ps_calc_18_bin_mean_range'\\n 'ps_calc_19_bin_median_range' 'ps_calc_19_bin_mean_range'\\n 'ps_calc_20_bin_median_range' 'ps_calc_20_bin_mean_range'\\n 'ps_ind_06_bin_median_range' 'ps_ind_06_bin_mean_range'\\n 'ps_ind_07_bin_median_range' 'ps_ind_07_bin_mean_range'\\n 'ps_ind_08_bin_median_range' 'ps_ind_08_bin_mean_range'\\n 'ps_ind_09_bin_median_range' 'ps_ind_09_bin_mean_range'\\n 'ps_ind_10_bin_median_range' 'ps_ind_10_bin_mean_range'\\n 'ps_ind_11_bin_median_range' 'ps_ind_11_bin_mean_range'\\n 'ps_ind_12_bin_median_range' 'ps_ind_12_bin_mean_range'\\n 'ps_ind_13_bin_median_range' 'ps_ind_13_bin_mean_range'\\n 'ps_ind_16_bin_median_range' 'ps_ind_16_bin_mean_range'\\n 'ps_ind_17_bin_median_range' 'ps_ind_17_bin_mean_range'\\n 'ps_ind_18_bin_median_range' 'ps_ind_18_bin_mean_range'\\n 'ps_calc_15_bin_median_range' 'ps_calc_15_bin_mean_range'\\n 'ps_calc_16_bin_median_range' 'ps_calc_16_bin_mean_range'\\n 'ps_calc_17_bin_median_range' 'ps_calc_17_bin_mean_range'\\n 'ps_calc_18_bin_median_range' 'ps_calc_18_bin_mean_range'\\n 'ps_calc_19_bin_median_range' 'ps_calc_19_bin_mean_range'\\n 'ps_calc_20_bin_median_range' 'ps_calc_20_bin_mean_range'] not in index\""
     ]
    }
   ],
   "source": [
    "trn_df = trn_df[train_features]\n",
    "sub_df = sub_df[train_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_df1 = trn_df.drop_duplicates(trn_df.columns.difference(['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_cats = [f for f in trn_df.columns if \"_cat\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in f_cats:\n",
    "    trn_df[f + \"_avg\"], sub_df[f + \"_avg\"] = target_encode(trn_series=trn_df[f],\n",
    "                                         tst_series=sub_df[f],\n",
    "                                         target=target,\n",
    "                                         min_samples_leaf=200,\n",
    "                                         smoothing=10,\n",
    "                                         noise_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sub_df = sub_df.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "n_estimators = 200\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=15) \n",
    "imp_df = np.zeros((len(trn_df.columns), n_splits))\n",
    "xgb_evals = np.zeros((n_estimators, n_splits))\n",
    "oof = np.empty(len(trn_df))\n",
    "sub_preds = np.zeros(len(sub_df))\n",
    "increase = True\n",
    "# np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for sp in np.linspace(1.0, 3.0, num=20):\n",
    "#     sp = 2.0\n",
    "#     Full OOF score : 0.284916\n",
    "#     Best mean score : 0.284269 + 0.011259 @ 113\n",
    "#     sp = 2.9\n",
    "#     Full OOF score : 0.284905\n",
    "#     Best mean score : 0.284473 + 0.010661 @ 123\n",
    "# 1.55555555556\n",
    "# Full OOF score : 0.285119\n",
    "# Best mean score : 0.284699 + 0.010672 @ 171\n",
    "# --------------------------------------\n",
    "np.random.seed(0)\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(target, target)):\n",
    "    trn_dat, trn_tgt = trn_df.iloc[trn_idx], target.iloc[trn_idx]\n",
    "    val_dat, val_tgt = trn_df.iloc[val_idx], target.iloc[val_idx]\n",
    "\n",
    "\n",
    "    # Upsample during cross validation to avoid having the same samples\n",
    "    # in both train and validation sets\n",
    "    # Validation set is not up-sampled to monitor overfitting\n",
    "    if increase:\n",
    "        # Get positive examples\n",
    "        pos = pd.Series(trn_tgt == 1)\n",
    "        # Add positive examples\n",
    "        trn_dat = pd.concat([trn_dat, trn_dat.loc[pos]], axis=0)\n",
    "        trn_tgt = pd.concat([trn_tgt, trn_tgt.loc[pos]], axis=0)\n",
    "        # Shuffle data\n",
    "        idx = np.arange(len(trn_dat))\n",
    "        np.random.shuffle(idx)\n",
    "        trn_dat = trn_dat.iloc[idx]\n",
    "        trn_tgt = trn_tgt.iloc[idx]\n",
    "\n",
    "#     print(sum(trn_tgt==0)/sum(trn_tgt==1))\n",
    "\n",
    "#     sp = sum(trn_tgt==0)/sum(trn_tgt==1)\n",
    "#         sp = 1.55556\n",
    "    sp = 1.52631578947\n",
    "    clf = XGBClassifier(n_estimators=n_estimators,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=.1, \n",
    "                        subsample=.8, \n",
    "                        colsample_bytree=.8,\n",
    "                        scale_pos_weight=sp,\n",
    "                        missing=-1,\n",
    "                        gamma=1,\n",
    "                        reg_alpha=0,\n",
    "                        reg_lambda=1,\n",
    "                        nthread=5)\n",
    "\n",
    "    clf.fit(trn_dat, trn_tgt, \n",
    "            eval_set=[(trn_dat, trn_tgt), (val_dat, val_tgt)],\n",
    "            eval_metric=gini_xgb,\n",
    "            early_stopping_rounds=None,\n",
    "            verbose=False)\n",
    "\n",
    "    # Keep feature importances\n",
    "    imp_df[:, fold_] = clf.feature_importances_\n",
    "\n",
    "    # Find best round for validation set\n",
    "    xgb_evals[:, fold_] = clf.evals_result_[\"validation_1\"][\"gini\"]\n",
    "    # Xgboost provides best round starting from 0 so it has to be incremented\n",
    "    best_round = np.argsort(xgb_evals[:, fold_])[::-1][0]\n",
    "    print(best_round)\n",
    "\n",
    "    # Predict OOF and submission probas with the best round\n",
    "    oof[val_idx] = clf.predict_proba(val_dat, ntree_limit=int(best_round))[:, 1]\n",
    "    # Update submission\n",
    "    sub_preds += clf.predict_proba(sub_df, ntree_limit=int(best_round))[:, 1] / n_splits\n",
    "\n",
    "    # Display results\n",
    "    print(\"Fold %2d : %.6f @%4d / best score is %.6f @%4d\"\n",
    "          % (fold_ + 1,\n",
    "             eval_gini(val_tgt, oof[val_idx]),\n",
    "             n_estimators,\n",
    "             xgb_evals[best_round, fold_],\n",
    "             best_round))\n",
    "\n",
    "print(sp)\n",
    "full_oof_score = eval_gini(target, oof)\n",
    "print(\"Full OOF score : %.6f\" % eval_gini(target, oof))\n",
    "# Compute mean score and std\n",
    "mean_eval = np.mean(xgb_evals, axis=1)\n",
    "std_eval = np.std(xgb_evals, axis=1)\n",
    "best_round = np.argsort(mean_eval)[::-1][0]\n",
    "\n",
    "print(\"Best mean score : %.6f + %.6f @%4d\"\n",
    "      % (mean_eval[best_round], std_eval[best_round], best_round))\n",
    "print('--------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_oof_score = eval_gini(target, oof)\n",
    "print(\"Full OOF score : %.6f\" % eval_gini(target, oof))\n",
    "# org with clipping, Full OOF score : 0.284952, LB: 0.275\n",
    "# org no clipping, Full OOF score : 0.284952, LB: 0.275\n",
    "# org, removed ntree_limit, kaggle/python: Full OOF score : 0.283630, LB: 0.274\n",
    "# org, with ntree_limit, kaggle/python: Full OOF score : 0.284745, LB: 0.282\n",
    "# org, with missing=-1, Full OOF score, no sp : 0.285726, LB:0.281\n",
    "# # org, with missing=-1, Full OOF score, sp : 0.283507, LB:\n",
    "# org with top 5 values means, med, skew, Kurt of 3 vas: 0.282344\n",
    "# org with top 2 values means, med, skew, Kurt of 3 vas: 0.283757, sub: 2017_11_27_20_27_58GMT, LB: 0.281\n",
    "# org with 1 value mmsk: 0.282906, LB: won't do\n",
    "# above with max_delta_step=1.1, removed sp: 0.0.285664, LB: won't do\n",
    "# above with calc features: 0.282900\n",
    "# org with 2 values mmsk: 0.286022, sub:2017_11_28_06_36_39, LB: 0.281\n",
    "# org with 4 car values mmsk, delta_step: 0.284071, sub:sub.xgb.0.28407065884695226.2017_11_28_07_01_03GMT, LB: \n",
    "# above with sp, no max_delta, 4 mmsk, sub.xgb.0.28059886243614096.2017_11_28_07_55_18GMT, LB:\n",
    "# about with sp=1.55556, 4 mmsk, ssub.xgb.0.2851186935146799.2017_11_28_19_38_05GMT, LB: 0.281\n",
    "# about with sp=1.55556, 4 mmsk, sub.xgb.0.2839886673471289.2017_11_28_20_28_27GMT, LB: 0.280\n",
    "# above + sp=1.52, sub.xgb.0.2845332509136781.2017_11_29_03_58_34GMT, LB: 0.281\n",
    "# took imp from features, Full OOF score : 0.285477, sub.xgb.0.2854771395865894.2017_11_29_04_43_17GMT, LB:0.280\n",
    "#0.284813\n",
    "#0.285085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute mean score and std\n",
    "mean_eval = np.mean(xgb_evals, axis=1)\n",
    "std_eval = np.std(xgb_evals, axis=1)\n",
    "best_round = np.argsort(mean_eval)[::-1][0]\n",
    "\n",
    "print(\"Best mean score : %.6f + %.6f @%4d\"\n",
    "      % (mean_eval[best_round], std_eval[best_round], best_round))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = sorted([(trn_df.columns[i], imp) for i, imp in enumerate(imp_df.mean(axis=1))],\n",
    "                     key=lambda x: x[1])\n",
    "\n",
    "for f, imp in importances[::-1]:\n",
    "    print(\"%-34s : %10.4f\" % (f, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df[\"target\"] = sub_preds\n",
    "now = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "fn = '../submissions/sub.xgb.{}.{}GMT'.format(full_oof_score, now)\n",
    "sub_df[[\"target\"]].to_csv(fn, index=True, float_format=\"%.9f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(trn_df['ps_reg_03'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(trn_df['ps_car_13'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.min(sub_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(sub_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = [int(round(x)) for x in sub_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y1 = [x for x in target.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = y1 + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['target'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = sub_df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.concat([trn_df, sub_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "n_estimators = 200\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=15) \n",
    "imp_df = np.zeros((len(X.columns), n_splits))\n",
    "xgb_evals = np.zeros((n_estimators, n_splits))\n",
    "oof = np.empty(len(X))\n",
    "sub_preds = np.zeros(len(sub_df))\n",
    "increase = True\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(target, target)):\n",
    "    trn_dat, trn_tgt = X.iloc[trn_idx], target.iloc[trn_idx]\n",
    "    val_dat, val_tgt = X.iloc[val_idx], target.iloc[val_idx]\n",
    "\n",
    "    \n",
    "    # Upsample during cross validation to avoid having the same samples\n",
    "    # in both train and validation sets\n",
    "    # Validation set is not up-sampled to monitor overfitting\n",
    "    if False:\n",
    "        # Get positive examples\n",
    "        pos = pd.Series(trn_tgt == 1)\n",
    "        # Add positive examples\n",
    "        trn_dat = pd.concat([trn_dat, trn_dat.loc[pos]], axis=0)\n",
    "        trn_tgt = pd.concat([trn_tgt, trn_tgt.loc[pos]], axis=0)\n",
    "        # Shuffle data\n",
    "        idx = np.arange(len(trn_dat))\n",
    "        np.random.shuffle(idx)\n",
    "        trn_dat = trn_dat.iloc[idx]\n",
    "        trn_tgt = trn_tgt.iloc[idx]\n",
    "    \n",
    "    print(sum(trn_tgt==0)/sum(trn_tgt==1))\n",
    "    \n",
    "    sp = sum(trn_tgt==0)/sum(trn_tgt==1)\n",
    "    clf = XGBClassifier(n_estimators=n_estimators,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=.1, \n",
    "                        subsample=.8, \n",
    "                        colsample_bytree=.8,\n",
    "                        scale_pos_weight =sp,\n",
    "                        missing=-1,\n",
    "                        gamma=1,\n",
    "                        reg_alpha=0,\n",
    "                        reg_lambda=1,\n",
    "                        nthread=5)\n",
    "    \n",
    "    clf.fit(trn_dat, trn_tgt, \n",
    "            eval_set=[(trn_dat, trn_tgt), (val_dat, val_tgt)],\n",
    "            eval_metric=gini_xgb,\n",
    "            early_stopping_rounds=None,\n",
    "            verbose=False)\n",
    "            \n",
    "    # Keep feature importances\n",
    "    imp_df[:, fold_] = clf.feature_importances_\n",
    "\n",
    "    # Find best round for validation set\n",
    "    xgb_evals[:, fold_] = clf.evals_result_[\"validation_1\"][\"gini\"]\n",
    "    # Xgboost provides best round starting from 0 so it has to be incremented\n",
    "    best_round = np.argsort(xgb_evals[:, fold_])[::-1][0]\n",
    "    print(best_round)\n",
    "    \n",
    "    # Predict OOF and submission probas with the best round\n",
    "    oof[val_idx] = clf.predict_proba(val_dat, ntree_limit=int(best_round))[:, 1]\n",
    "    # Update submission\n",
    "    sub_preds += clf.predict_proba(sub_df, ntree_limit=int(best_round))[:, 1] / n_splits\n",
    "\n",
    "    # Display results\n",
    "    print(\"Fold %2d : %.6f @%4d / best score is %.6f @%4d\"\n",
    "          % (fold_ + 1,\n",
    "             eval_gini(val_tgt, oof[val_idx]),\n",
    "             n_estimators,\n",
    "             xgb_evals[best_round, fold_],\n",
    "             best_round))\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.min(sub_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(sub_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df[\"target\"] = sub_preds\n",
    "now = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "fn = '../submissions/sub.xgb.{}GMT'.format(now)\n",
    "sub_df[[\"target\"]].to_csv(fn, index=True, float_format=\"%.9f\")\n",
    "# 0.274 on pblic LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
