{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather\n",
    "\n",
    "from numba import jit\n",
    "import time\n",
    "import gc\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pickle\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "\n",
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "# Funcitons from olivier's kernel\n",
    "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "def gini_lgbm(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = eval_gini(labels, preds)\n",
    "    return [('gini', gini_score, True)]\n",
    "\n",
    "def gini_normalized(a, p):\n",
    "    return eval_gini(a, p) / eval_gini(a, a)\n",
    "\n",
    "gini_scorer = make_scorer(gini_normalized, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../cache/train_labels.csv')\n",
    "target = df['y']\n",
    "y = df['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_df = feather.read_dataframe('../cache/trn_df.feather')\n",
    "sub_df = feather.read_dataframe('../cache/sub_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 227)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 432)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = sub_df[trn_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 227)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([573518,  21694])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.51891309,  13.71835531])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "595212 / (2 * np.bincount(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wts = [0.947635485 if x==1 else 0.03644752 for x in target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves':[150,200,300], 'max_depth':[4,7,10],\n",
    "          'learning_rate':[0.05,0.03, 0.01, 0.08],'max_bin':[100,200,400], 'n_estimators': [100,200,400]}\n",
    "\n",
    "\n",
    "lgbm = LGBMClassifier(objective='binary:logistic', sample_weight=wts)\n",
    "\n",
    "\n",
    "\n",
    "clf = RandomizedSearchCV(lgbm, params, n_jobs=4, \n",
    "                   cv=StratifiedKFold(y, 5, True),\n",
    "                   scoring = gini_scorer,\n",
    "                   verbose=3, refit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] num_leaves=150, n_estimators=200, learning_rate=0.01, max_bin=400, max_depth=10 \n",
      "[CV] num_leaves=150, n_estimators=200, learning_rate=0.01, max_bin=400, max_depth=10 \n",
      "[CV] num_leaves=150, n_estimators=200, learning_rate=0.01, max_bin=400, max_depth=10 \n",
      "[CV] num_leaves=150, n_estimators=200, learning_rate=0.01, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=150, n_estimators=200, learning_rate=0.01, max_bin=400, max_depth=10, score=0.002134 -50.8min\n",
      "[CV] num_leaves=150, n_estimators=200, learning_rate=0.01, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=150, n_estimators=200, learning_rate=0.01, max_bin=400, max_depth=10, score=-0.002848 -50.8min\n",
      "[CV] num_leaves=150, n_estimators=400, learning_rate=0.05, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=150, n_estimators=200, learning_rate=0.01, max_bin=400, max_depth=10, score=-0.007631 -51.4min\n",
      "[CV] num_leaves=150, n_estimators=400, learning_rate=0.05, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=150, n_estimators=200, learning_rate=0.01, max_bin=400, max_depth=10, score=0.002223 -51.6min\n",
      "[CV] num_leaves=150, n_estimators=400, learning_rate=0.05, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=150, n_estimators=200, learning_rate=0.01, max_bin=400, max_depth=10, score=0.005580 -51.3min\n",
      "[CV] num_leaves=150, n_estimators=400, learning_rate=0.05, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=150, n_estimators=400, learning_rate=0.05, max_bin=400, max_depth=10, score=0.002797 -53.3min\n",
      "[CV] num_leaves=150, n_estimators=400, learning_rate=0.05, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=150, n_estimators=400, learning_rate=0.05, max_bin=400, max_depth=10, score=0.010845 -53.7min\n",
      "[CV] num_leaves=300, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=150, n_estimators=400, learning_rate=0.05, max_bin=400, max_depth=10, score=0.007002 -53.9min\n",
      "[CV] num_leaves=300, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=150, n_estimators=400, learning_rate=0.05, max_bin=400, max_depth=10, score=0.015508 -50.8min\n",
      "[CV] num_leaves=300, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=150, n_estimators=400, learning_rate=0.05, max_bin=400, max_depth=10, score=0.011450 -50.3min\n",
      "[CV] num_leaves=300, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10, score=-0.008283 -53.1min\n",
      "[CV] num_leaves=300, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10, score=0.003564 -53.6min\n",
      "[CV] num_leaves=200, n_estimators=200, learning_rate=0.03, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=200, n_estimators=200, learning_rate=0.03, max_bin=400, max_depth=10, score=-0.007288 -48.6min\n",
      "[CV] num_leaves=200, n_estimators=200, learning_rate=0.03, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10, score=0.004220 -53.8min\n",
      "[CV] num_leaves=200, n_estimators=200, learning_rate=0.03, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10, score=-0.001189 -55.4min\n",
      "[CV] num_leaves=200, n_estimators=200, learning_rate=0.03, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10, score=0.005812 -55.6min\n",
      "[CV] num_leaves=200, n_estimators=200, learning_rate=0.03, max_bin=400, max_depth=10 \n",
      "[CV]  num_leaves=200, n_estimators=200, learning_rate=0.03, max_bin=400, max_depth=10, score=0.001860 -51.7min\n",
      "[CV] num_leaves=200, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=200, n_estimators=200, learning_rate=0.03, max_bin=400, max_depth=10, score=0.003613 -51.8min\n",
      "[CV] num_leaves=200, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=200, n_estimators=200, learning_rate=0.03, max_bin=400, max_depth=10, score=-0.002250 -52.2min\n",
      "[CV] num_leaves=200, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=200, n_estimators=200, learning_rate=0.03, max_bin=400, max_depth=10, score=0.005965 -51.2min\n",
      "[CV] num_leaves=200, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=200, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10, score=-0.007738 -49.7min\n",
      "[CV] num_leaves=200, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=200, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10, score=0.005833 -49.6min\n",
      "[CV] num_leaves=300, n_estimators=400, learning_rate=0.01, max_bin=400, max_depth=4 \n",
      "[CV]  num_leaves=200, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10, score=-0.001148 -51.0min\n",
      "[CV] num_leaves=300, n_estimators=400, learning_rate=0.01, max_bin=400, max_depth=4 \n",
      "[CV]  num_leaves=200, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10, score=0.003637 -49.5min\n",
      "[CV] num_leaves=300, n_estimators=400, learning_rate=0.01, max_bin=400, max_depth=4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 314.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  num_leaves=300, n_estimators=400, learning_rate=0.01, max_bin=400, max_depth=4, score=-0.009653 -11.1min\n",
      "[CV] num_leaves=300, n_estimators=400, learning_rate=0.01, max_bin=400, max_depth=4 \n",
      "[CV]  num_leaves=300, n_estimators=400, learning_rate=0.01, max_bin=400, max_depth=4, score=0.000609 -11.0min\n",
      "[CV] num_leaves=300, n_estimators=400, learning_rate=0.01, max_bin=400, max_depth=4 \n",
      "[CV]  num_leaves=300, n_estimators=400, learning_rate=0.01, max_bin=400, max_depth=4, score=-0.004434 -10.9min\n",
      "[CV] num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=4 \n",
      "[CV]  num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=4, score=-0.009653 - 2.9min\n",
      "[CV] num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=4 \n",
      "[CV]  num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=4, score=0.000609 - 2.9min\n",
      "[CV] num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=4 \n",
      "[CV]  num_leaves=300, n_estimators=400, learning_rate=0.01, max_bin=400, max_depth=4, score=0.002160 -10.7min\n",
      "[CV] num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=4 \n",
      "[CV]  num_leaves=300, n_estimators=400, learning_rate=0.01, max_bin=400, max_depth=4, score=0.004416 -10.7min\n",
      "[CV] num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=4 \n",
      "[CV]  num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=4, score=-0.004434 - 2.9min\n",
      "[CV] num_leaves=300, n_estimators=400, learning_rate=0.03, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=4, score=0.002160 - 2.9min\n",
      "[CV] num_leaves=300, n_estimators=400, learning_rate=0.03, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=4, score=0.004416 - 2.9min\n",
      "[CV] num_leaves=300, n_estimators=400, learning_rate=0.03, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=200, n_estimators=200, learning_rate=0.05, max_bin=200, max_depth=10, score=0.005068 -49.8min\n",
      "[CV] num_leaves=300, n_estimators=400, learning_rate=0.03, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=400, learning_rate=0.03, max_bin=200, max_depth=10, score=-0.006931 -101.4min\n",
      "[CV] num_leaves=300, n_estimators=400, learning_rate=0.03, max_bin=200, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=400, learning_rate=0.03, max_bin=200, max_depth=10, score=0.006001 -103.3min\n",
      "[CV] num_leaves=200, n_estimators=400, learning_rate=0.08, max_bin=200, max_depth=4 \n",
      "[CV]  num_leaves=300, n_estimators=400, learning_rate=0.03, max_bin=200, max_depth=10, score=-0.000460 -103.1min\n",
      "[CV] num_leaves=200, n_estimators=400, learning_rate=0.08, max_bin=200, max_depth=4 \n",
      "[CV]  num_leaves=200, n_estimators=400, learning_rate=0.08, max_bin=200, max_depth=4, score=-0.009365 - 8.1min\n",
      "[CV] num_leaves=200, n_estimators=400, learning_rate=0.08, max_bin=200, max_depth=4 \n",
      "[CV]  num_leaves=200, n_estimators=400, learning_rate=0.08, max_bin=200, max_depth=4, score=0.003829 - 8.2min\n",
      "[CV] num_leaves=200, n_estimators=400, learning_rate=0.08, max_bin=200, max_depth=4 \n",
      "[CV]  num_leaves=200, n_estimators=400, learning_rate=0.08, max_bin=200, max_depth=4, score=-0.003297 - 8.0min\n",
      "[CV] num_leaves=200, n_estimators=400, learning_rate=0.08, max_bin=200, max_depth=4 \n",
      "[CV]  num_leaves=200, n_estimators=400, learning_rate=0.08, max_bin=200, max_depth=4, score=0.003769 - 8.1min\n",
      "[CV] num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=400, learning_rate=0.03, max_bin=200, max_depth=10, score=0.006012 -98.8min\n",
      "[CV] num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=10 \n",
      "[CV]  num_leaves=200, n_estimators=400, learning_rate=0.08, max_bin=200, max_depth=4, score=0.005332 - 8.0min\n",
      "[CV] num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=10, score=-0.009365 -42.7min\n",
      "[CV] num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=10, score=0.001130 -42.5min\n",
      "[CV] num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=10 \n",
      "[CV]  num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=10, score=-0.002935 -42.7min\n",
      "[CV]  num_leaves=300, n_estimators=400, learning_rate=0.03, max_bin=200, max_depth=10, score=0.005432 -88.4min\n",
      "[CV]  num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=10, score=0.002637 -32.3min\n",
      "[CV]  num_leaves=300, n_estimators=100, learning_rate=0.03, max_bin=100, max_depth=10, score=0.004416 -30.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed: 531.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[0 0 ..., 0 0], n_folds=5, shuffle=True, random_state=None),\n",
       "          error_score='raise',\n",
       "          estimator=LGBMClassifier(boosting_type='gbdt', colsample_bytree=1.0, learning_rate=0.1,\n",
       "        max_bin=255, max_depth=-1, min_child_samples=10,\n",
       "        min_child_weight=5, min_split_gain=0.0, n_estimators=10, n_jobs=-1,\n",
       "        num_leaves=31, objective='binary:logistic', random_state=0,\n",
       "        reg... 0.03644752],\n",
       "        silent=True, subsample=1.0, subsample_for_bin=50000,\n",
       "        subsample_freq=1),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=4,\n",
       "          param_distributions={'num_leaves': [150, 200, 300], 'n_estimators': [100, 200, 400], 'learning_rate': [0.05, 0.03, 0.01, 0.08], 'max_bin': [100, 200, 400], 'max_depth': [4, 7, 10]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          scoring=make_scorer(gini_normalized), verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(trn_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009520515552805779\n",
      "{'num_leaves': 150, 'n_estimators': 400, 'learning_rate': 0.05, 'max_bin': 400, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../cache/idx_info.pkl', 'rb') as f:\n",
    "    idx_info= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(892816, 227)\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "n_estimators = 200\n",
    "#folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=15) \n",
    "imp_df = np.zeros((len(trn_df.columns), n_splits))\n",
    "lgbm_evals = np.zeros((n_estimators, n_splits))\n",
    "oof_lgbm = np.empty(len(trn_df))\n",
    "sub_preds = np.zeros(len(sub_df))\n",
    "tgt = df['y']\n",
    "sub_df = feather.read_dataframe('../cache/sub_df.feather')\n",
    "sub_df = sub_df[trn_df.columns]\n",
    "sub_df.fillna(-1, inplace=True)\n",
    "print(sub_df.shape)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'gini',\n",
    "    'num_leaves': 150,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_bin': 400,\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 400,\n",
    "    'verbose': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's gini: 0.211688\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\tvalid_0's gini: 0.230021\n",
      "[3]\tvalid_0's gini: 0.24114\n",
      "[4]\tvalid_0's gini: 0.247334\n",
      "[5]\tvalid_0's gini: 0.255675\n",
      "[6]\tvalid_0's gini: 0.265633\n",
      "[7]\tvalid_0's gini: 0.265896\n",
      "[8]\tvalid_0's gini: 0.270041\n",
      "[9]\tvalid_0's gini: 0.277607\n",
      "[10]\tvalid_0's gini: 0.278591\n",
      "[11]\tvalid_0's gini: 0.281882\n",
      "[12]\tvalid_0's gini: 0.282922\n",
      "[13]\tvalid_0's gini: 0.285759\n",
      "[14]\tvalid_0's gini: 0.288482\n",
      "[15]\tvalid_0's gini: 0.291393\n",
      "[16]\tvalid_0's gini: 0.293939\n",
      "[17]\tvalid_0's gini: 0.297432\n",
      "[18]\tvalid_0's gini: 0.301979\n",
      "[19]\tvalid_0's gini: 0.30393\n",
      "[20]\tvalid_0's gini: 0.306387\n",
      "[21]\tvalid_0's gini: 0.307441\n",
      "[22]\tvalid_0's gini: 0.309646\n",
      "[23]\tvalid_0's gini: 0.311447\n",
      "[24]\tvalid_0's gini: 0.315373\n",
      "[25]\tvalid_0's gini: 0.31714\n",
      "[26]\tvalid_0's gini: 0.318582\n",
      "[27]\tvalid_0's gini: 0.318926\n",
      "[28]\tvalid_0's gini: 0.319927\n",
      "[29]\tvalid_0's gini: 0.322254\n",
      "[30]\tvalid_0's gini: 0.325918\n",
      "[31]\tvalid_0's gini: 0.326838\n",
      "[32]\tvalid_0's gini: 0.328851\n",
      "[33]\tvalid_0's gini: 0.330646\n",
      "[34]\tvalid_0's gini: 0.331579\n",
      "[35]\tvalid_0's gini: 0.332037\n",
      "[36]\tvalid_0's gini: 0.333331\n",
      "[37]\tvalid_0's gini: 0.3347\n",
      "[38]\tvalid_0's gini: 0.336216\n",
      "[39]\tvalid_0's gini: 0.337167\n",
      "[40]\tvalid_0's gini: 0.338778\n",
      "[41]\tvalid_0's gini: 0.34161\n",
      "[42]\tvalid_0's gini: 0.343249\n",
      "[43]\tvalid_0's gini: 0.345318\n",
      "[44]\tvalid_0's gini: 0.346307\n",
      "[45]\tvalid_0's gini: 0.347521\n",
      "[46]\tvalid_0's gini: 0.349462\n",
      "[47]\tvalid_0's gini: 0.350465\n",
      "[48]\tvalid_0's gini: 0.35246\n",
      "[49]\tvalid_0's gini: 0.352624\n",
      "[50]\tvalid_0's gini: 0.354374\n",
      "[51]\tvalid_0's gini: 0.356053\n",
      "[52]\tvalid_0's gini: 0.358371\n",
      "[53]\tvalid_0's gini: 0.360805\n",
      "[54]\tvalid_0's gini: 0.362268\n",
      "[55]\tvalid_0's gini: 0.363104\n",
      "[56]\tvalid_0's gini: 0.364533\n",
      "[57]\tvalid_0's gini: 0.36588\n",
      "[58]\tvalid_0's gini: 0.365893\n",
      "[59]\tvalid_0's gini: 0.367218\n",
      "[60]\tvalid_0's gini: 0.366907\n",
      "[61]\tvalid_0's gini: 0.366325\n",
      "[62]\tvalid_0's gini: 0.366423\n",
      "[63]\tvalid_0's gini: 0.367871\n",
      "[64]\tvalid_0's gini: 0.369587\n",
      "[65]\tvalid_0's gini: 0.370852\n",
      "[66]\tvalid_0's gini: 0.371453\n",
      "[67]\tvalid_0's gini: 0.372138\n",
      "[68]\tvalid_0's gini: 0.372999\n",
      "[69]\tvalid_0's gini: 0.373669\n",
      "[70]\tvalid_0's gini: 0.37307\n",
      "[71]\tvalid_0's gini: 0.373406\n",
      "[72]\tvalid_0's gini: 0.373935\n",
      "[73]\tvalid_0's gini: 0.373709\n",
      "[74]\tvalid_0's gini: 0.374123\n",
      "[75]\tvalid_0's gini: 0.374343\n",
      "[76]\tvalid_0's gini: 0.374691\n",
      "[77]\tvalid_0's gini: 0.375327\n",
      "[78]\tvalid_0's gini: 0.376635\n",
      "[79]\tvalid_0's gini: 0.379808\n",
      "[80]\tvalid_0's gini: 0.379639\n",
      "[81]\tvalid_0's gini: 0.37966\n",
      "[82]\tvalid_0's gini: 0.379587\n",
      "[83]\tvalid_0's gini: 0.380037\n",
      "[84]\tvalid_0's gini: 0.379421\n",
      "[85]\tvalid_0's gini: 0.379159\n",
      "[86]\tvalid_0's gini: 0.379792\n",
      "[87]\tvalid_0's gini: 0.379378\n",
      "[88]\tvalid_0's gini: 0.379075\n",
      "[89]\tvalid_0's gini: 0.379159\n",
      "[90]\tvalid_0's gini: 0.379714\n",
      "[91]\tvalid_0's gini: 0.379729\n",
      "[92]\tvalid_0's gini: 0.380181\n",
      "[93]\tvalid_0's gini: 0.380026\n",
      "[94]\tvalid_0's gini: 0.380384\n",
      "[95]\tvalid_0's gini: 0.380318\n",
      "[96]\tvalid_0's gini: 0.381271\n",
      "[97]\tvalid_0's gini: 0.381357\n",
      "[98]\tvalid_0's gini: 0.381777\n",
      "[99]\tvalid_0's gini: 0.381814\n",
      "[100]\tvalid_0's gini: 0.381292\n",
      "[101]\tvalid_0's gini: 0.3813\n",
      "[102]\tvalid_0's gini: 0.381516\n",
      "[103]\tvalid_0's gini: 0.381455\n",
      "[104]\tvalid_0's gini: 0.382161\n",
      "[105]\tvalid_0's gini: 0.382718\n",
      "[106]\tvalid_0's gini: 0.382739\n",
      "[107]\tvalid_0's gini: 0.382868\n",
      "[108]\tvalid_0's gini: 0.38273\n",
      "[109]\tvalid_0's gini: 0.384356\n",
      "[110]\tvalid_0's gini: 0.384724\n",
      "[111]\tvalid_0's gini: 0.384411\n",
      "[112]\tvalid_0's gini: 0.384771\n",
      "[113]\tvalid_0's gini: 0.385476\n",
      "[114]\tvalid_0's gini: 0.385421\n",
      "[115]\tvalid_0's gini: 0.385548\n",
      "[116]\tvalid_0's gini: 0.386963\n",
      "[117]\tvalid_0's gini: 0.386911\n",
      "[118]\tvalid_0's gini: 0.386587\n",
      "[119]\tvalid_0's gini: 0.387098\n",
      "[120]\tvalid_0's gini: 0.386837\n",
      "[121]\tvalid_0's gini: 0.386685\n",
      "[122]\tvalid_0's gini: 0.38718\n",
      "[123]\tvalid_0's gini: 0.38681\n",
      "[124]\tvalid_0's gini: 0.386829\n",
      "[125]\tvalid_0's gini: 0.38711\n",
      "[126]\tvalid_0's gini: 0.386575\n",
      "[127]\tvalid_0's gini: 0.386997\n",
      "[128]\tvalid_0's gini: 0.387335\n",
      "[129]\tvalid_0's gini: 0.388097\n",
      "[130]\tvalid_0's gini: 0.387794\n",
      "[131]\tvalid_0's gini: 0.38804\n",
      "[132]\tvalid_0's gini: 0.388492\n",
      "[133]\tvalid_0's gini: 0.389036\n",
      "[134]\tvalid_0's gini: 0.389264\n",
      "[135]\tvalid_0's gini: 0.388844\n",
      "[136]\tvalid_0's gini: 0.389061\n",
      "[137]\tvalid_0's gini: 0.388528\n",
      "[138]\tvalid_0's gini: 0.388552\n",
      "[139]\tvalid_0's gini: 0.388677\n",
      "[140]\tvalid_0's gini: 0.389065\n",
      "[141]\tvalid_0's gini: 0.3889\n",
      "[142]\tvalid_0's gini: 0.388431\n",
      "[143]\tvalid_0's gini: 0.388254\n",
      "[144]\tvalid_0's gini: 0.388238\n",
      "[145]\tvalid_0's gini: 0.38823\n",
      "[146]\tvalid_0's gini: 0.388712\n",
      "[147]\tvalid_0's gini: 0.388783\n",
      "[148]\tvalid_0's gini: 0.389089\n",
      "[149]\tvalid_0's gini: 0.389152\n",
      "[150]\tvalid_0's gini: 0.388753\n",
      "[151]\tvalid_0's gini: 0.388407\n",
      "[152]\tvalid_0's gini: 0.388322\n",
      "[153]\tvalid_0's gini: 0.388749\n",
      "[154]\tvalid_0's gini: 0.388839\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's gini: 0.389264\n",
      "Fold  1 : 0.389264 @ 200 \n",
      "[1]\tvalid_0's gini: 0.211344\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\tvalid_0's gini: 0.223511\n",
      "[3]\tvalid_0's gini: 0.231993\n",
      "[4]\tvalid_0's gini: 0.240447\n",
      "[5]\tvalid_0's gini: 0.249315\n",
      "[6]\tvalid_0's gini: 0.261565\n",
      "[7]\tvalid_0's gini: 0.263978\n",
      "[8]\tvalid_0's gini: 0.270244\n",
      "[9]\tvalid_0's gini: 0.271944\n",
      "[10]\tvalid_0's gini: 0.274302\n",
      "[11]\tvalid_0's gini: 0.277604\n",
      "[12]\tvalid_0's gini: 0.280101\n",
      "[13]\tvalid_0's gini: 0.284668\n",
      "[14]\tvalid_0's gini: 0.288538\n",
      "[15]\tvalid_0's gini: 0.289161\n",
      "[16]\tvalid_0's gini: 0.291729\n",
      "[17]\tvalid_0's gini: 0.293774\n",
      "[18]\tvalid_0's gini: 0.295266\n",
      "[19]\tvalid_0's gini: 0.297142\n",
      "[20]\tvalid_0's gini: 0.299163\n",
      "[21]\tvalid_0's gini: 0.30239\n",
      "[22]\tvalid_0's gini: 0.303476\n",
      "[23]\tvalid_0's gini: 0.304863\n",
      "[24]\tvalid_0's gini: 0.307057\n",
      "[25]\tvalid_0's gini: 0.311511\n",
      "[26]\tvalid_0's gini: 0.31602\n",
      "[27]\tvalid_0's gini: 0.317483\n",
      "[28]\tvalid_0's gini: 0.320406\n",
      "[29]\tvalid_0's gini: 0.321095\n",
      "[30]\tvalid_0's gini: 0.325302\n",
      "[31]\tvalid_0's gini: 0.32729\n",
      "[32]\tvalid_0's gini: 0.330738\n",
      "[33]\tvalid_0's gini: 0.331056\n",
      "[34]\tvalid_0's gini: 0.333235\n",
      "[35]\tvalid_0's gini: 0.336361\n",
      "[36]\tvalid_0's gini: 0.338521\n",
      "[37]\tvalid_0's gini: 0.340319\n",
      "[38]\tvalid_0's gini: 0.341332\n",
      "[39]\tvalid_0's gini: 0.346301\n",
      "[40]\tvalid_0's gini: 0.346864\n",
      "[41]\tvalid_0's gini: 0.348896\n",
      "[42]\tvalid_0's gini: 0.350768\n",
      "[43]\tvalid_0's gini: 0.352922\n",
      "[44]\tvalid_0's gini: 0.353801\n",
      "[45]\tvalid_0's gini: 0.357057\n",
      "[46]\tvalid_0's gini: 0.358247\n",
      "[47]\tvalid_0's gini: 0.360045\n",
      "[48]\tvalid_0's gini: 0.361226\n",
      "[49]\tvalid_0's gini: 0.362082\n",
      "[50]\tvalid_0's gini: 0.362923\n",
      "[51]\tvalid_0's gini: 0.365306\n",
      "[52]\tvalid_0's gini: 0.366307\n",
      "[53]\tvalid_0's gini: 0.36774\n",
      "[54]\tvalid_0's gini: 0.36802\n",
      "[55]\tvalid_0's gini: 0.36855\n",
      "[56]\tvalid_0's gini: 0.369603\n",
      "[57]\tvalid_0's gini: 0.369918\n",
      "[58]\tvalid_0's gini: 0.370674\n",
      "[59]\tvalid_0's gini: 0.370298\n",
      "[60]\tvalid_0's gini: 0.371475\n",
      "[61]\tvalid_0's gini: 0.37226\n",
      "[62]\tvalid_0's gini: 0.372681\n",
      "[63]\tvalid_0's gini: 0.372726\n",
      "[64]\tvalid_0's gini: 0.372939\n",
      "[65]\tvalid_0's gini: 0.37307\n",
      "[66]\tvalid_0's gini: 0.373623\n",
      "[67]\tvalid_0's gini: 0.373393\n",
      "[68]\tvalid_0's gini: 0.374125\n",
      "[69]\tvalid_0's gini: 0.374389\n",
      "[70]\tvalid_0's gini: 0.374844\n",
      "[71]\tvalid_0's gini: 0.375664\n",
      "[72]\tvalid_0's gini: 0.37676\n",
      "[73]\tvalid_0's gini: 0.376658\n",
      "[74]\tvalid_0's gini: 0.376899\n",
      "[75]\tvalid_0's gini: 0.376841\n",
      "[76]\tvalid_0's gini: 0.377031\n",
      "[77]\tvalid_0's gini: 0.37792\n",
      "[78]\tvalid_0's gini: 0.378542\n",
      "[79]\tvalid_0's gini: 0.3786\n",
      "[80]\tvalid_0's gini: 0.378306\n",
      "[81]\tvalid_0's gini: 0.378991\n",
      "[82]\tvalid_0's gini: 0.379915\n",
      "[83]\tvalid_0's gini: 0.380323\n",
      "[84]\tvalid_0's gini: 0.380076\n",
      "[85]\tvalid_0's gini: 0.379719\n",
      "[86]\tvalid_0's gini: 0.38008\n",
      "[87]\tvalid_0's gini: 0.381147\n",
      "[88]\tvalid_0's gini: 0.38159\n",
      "[89]\tvalid_0's gini: 0.382482\n",
      "[90]\tvalid_0's gini: 0.383275\n",
      "[91]\tvalid_0's gini: 0.383612\n",
      "[92]\tvalid_0's gini: 0.384048\n",
      "[93]\tvalid_0's gini: 0.384328\n",
      "[94]\tvalid_0's gini: 0.383887\n",
      "[95]\tvalid_0's gini: 0.384142\n",
      "[96]\tvalid_0's gini: 0.384486\n",
      "[97]\tvalid_0's gini: 0.383834\n",
      "[98]\tvalid_0's gini: 0.38382\n",
      "[99]\tvalid_0's gini: 0.383684\n",
      "[100]\tvalid_0's gini: 0.383976\n",
      "[101]\tvalid_0's gini: 0.384023\n",
      "[102]\tvalid_0's gini: 0.386394\n",
      "[103]\tvalid_0's gini: 0.386444\n",
      "[104]\tvalid_0's gini: 0.386757\n",
      "[105]\tvalid_0's gini: 0.387445\n",
      "[106]\tvalid_0's gini: 0.38747\n",
      "[107]\tvalid_0's gini: 0.387408\n",
      "[108]\tvalid_0's gini: 0.388857\n",
      "[109]\tvalid_0's gini: 0.388753\n",
      "[110]\tvalid_0's gini: 0.388951\n",
      "[111]\tvalid_0's gini: 0.389037\n",
      "[112]\tvalid_0's gini: 0.389493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113]\tvalid_0's gini: 0.390767\n",
      "[114]\tvalid_0's gini: 0.390929\n",
      "[115]\tvalid_0's gini: 0.39069\n",
      "[116]\tvalid_0's gini: 0.390417\n",
      "[117]\tvalid_0's gini: 0.390189\n",
      "[118]\tvalid_0's gini: 0.390115\n",
      "[119]\tvalid_0's gini: 0.390361\n",
      "[120]\tvalid_0's gini: 0.390644\n",
      "[121]\tvalid_0's gini: 0.390295\n",
      "[122]\tvalid_0's gini: 0.39033\n",
      "[123]\tvalid_0's gini: 0.390014\n",
      "[124]\tvalid_0's gini: 0.38987\n",
      "[125]\tvalid_0's gini: 0.39017\n",
      "[126]\tvalid_0's gini: 0.390638\n",
      "[127]\tvalid_0's gini: 0.390284\n",
      "[128]\tvalid_0's gini: 0.390647\n",
      "[129]\tvalid_0's gini: 0.391319\n",
      "[130]\tvalid_0's gini: 0.391403\n",
      "[131]\tvalid_0's gini: 0.391126\n",
      "[132]\tvalid_0's gini: 0.391556\n",
      "[133]\tvalid_0's gini: 0.391663\n",
      "[134]\tvalid_0's gini: 0.391857\n",
      "[135]\tvalid_0's gini: 0.391719\n",
      "[136]\tvalid_0's gini: 0.391897\n",
      "[137]\tvalid_0's gini: 0.393837\n",
      "[138]\tvalid_0's gini: 0.394336\n",
      "[139]\tvalid_0's gini: 0.393529\n",
      "[140]\tvalid_0's gini: 0.393282\n",
      "[141]\tvalid_0's gini: 0.392739\n",
      "[142]\tvalid_0's gini: 0.392248\n",
      "[143]\tvalid_0's gini: 0.392624\n",
      "[144]\tvalid_0's gini: 0.392434\n",
      "[145]\tvalid_0's gini: 0.39273\n",
      "[146]\tvalid_0's gini: 0.392626\n",
      "[147]\tvalid_0's gini: 0.393115\n",
      "[148]\tvalid_0's gini: 0.394253\n",
      "[149]\tvalid_0's gini: 0.394794\n",
      "[150]\tvalid_0's gini: 0.394444\n",
      "[151]\tvalid_0's gini: 0.394576\n",
      "[152]\tvalid_0's gini: 0.394823\n",
      "[153]\tvalid_0's gini: 0.39614\n",
      "[154]\tvalid_0's gini: 0.396894\n",
      "[155]\tvalid_0's gini: 0.396574\n",
      "[156]\tvalid_0's gini: 0.396827\n",
      "[157]\tvalid_0's gini: 0.396634\n",
      "[158]\tvalid_0's gini: 0.397005\n",
      "[159]\tvalid_0's gini: 0.396925\n",
      "[160]\tvalid_0's gini: 0.396819\n",
      "[161]\tvalid_0's gini: 0.396418\n",
      "[162]\tvalid_0's gini: 0.396315\n",
      "[163]\tvalid_0's gini: 0.397177\n",
      "[164]\tvalid_0's gini: 0.397111\n",
      "[165]\tvalid_0's gini: 0.396692\n",
      "[166]\tvalid_0's gini: 0.396881\n",
      "[167]\tvalid_0's gini: 0.396751\n",
      "[168]\tvalid_0's gini: 0.396561\n",
      "[169]\tvalid_0's gini: 0.396616\n",
      "[170]\tvalid_0's gini: 0.396362\n",
      "[171]\tvalid_0's gini: 0.397063\n",
      "[172]\tvalid_0's gini: 0.397759\n",
      "[173]\tvalid_0's gini: 0.397832\n",
      "[174]\tvalid_0's gini: 0.397905\n",
      "[175]\tvalid_0's gini: 0.398592\n",
      "[176]\tvalid_0's gini: 0.3983\n",
      "[177]\tvalid_0's gini: 0.397841\n",
      "[178]\tvalid_0's gini: 0.397974\n",
      "[179]\tvalid_0's gini: 0.3978\n",
      "[180]\tvalid_0's gini: 0.398012\n",
      "[181]\tvalid_0's gini: 0.397954\n",
      "[182]\tvalid_0's gini: 0.398614\n",
      "[183]\tvalid_0's gini: 0.399069\n",
      "[184]\tvalid_0's gini: 0.39872\n",
      "[185]\tvalid_0's gini: 0.398491\n",
      "[186]\tvalid_0's gini: 0.398108\n",
      "[187]\tvalid_0's gini: 0.397927\n",
      "[188]\tvalid_0's gini: 0.397885\n",
      "[189]\tvalid_0's gini: 0.397621\n",
      "[190]\tvalid_0's gini: 0.397914\n",
      "[191]\tvalid_0's gini: 0.39987\n",
      "[192]\tvalid_0's gini: 0.400616\n",
      "[193]\tvalid_0's gini: 0.400382\n",
      "[194]\tvalid_0's gini: 0.400996\n",
      "[195]\tvalid_0's gini: 0.401335\n",
      "[196]\tvalid_0's gini: 0.401923\n",
      "[197]\tvalid_0's gini: 0.401393\n",
      "[198]\tvalid_0's gini: 0.401224\n",
      "[199]\tvalid_0's gini: 0.400916\n",
      "[200]\tvalid_0's gini: 0.400493\n",
      "Fold  2 : 0.400493 @ 200 \n",
      "[1]\tvalid_0's gini: 0.207542\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\tvalid_0's gini: 0.256008\n",
      "[3]\tvalid_0's gini: 0.260697\n",
      "[4]\tvalid_0's gini: 0.264589\n",
      "[5]\tvalid_0's gini: 0.274603\n",
      "[6]\tvalid_0's gini: 0.279336\n",
      "[7]\tvalid_0's gini: 0.282286\n",
      "[8]\tvalid_0's gini: 0.285456\n",
      "[9]\tvalid_0's gini: 0.290882\n",
      "[10]\tvalid_0's gini: 0.294579\n",
      "[11]\tvalid_0's gini: 0.29796\n",
      "[12]\tvalid_0's gini: 0.301567\n",
      "[13]\tvalid_0's gini: 0.303535\n",
      "[14]\tvalid_0's gini: 0.30453\n",
      "[15]\tvalid_0's gini: 0.306081\n",
      "[16]\tvalid_0's gini: 0.31004\n",
      "[17]\tvalid_0's gini: 0.311368\n",
      "[18]\tvalid_0's gini: 0.310871\n",
      "[19]\tvalid_0's gini: 0.318356\n",
      "[20]\tvalid_0's gini: 0.319769\n",
      "[21]\tvalid_0's gini: 0.320115\n",
      "[22]\tvalid_0's gini: 0.326537\n",
      "[23]\tvalid_0's gini: 0.327284\n",
      "[24]\tvalid_0's gini: 0.329474\n",
      "[25]\tvalid_0's gini: 0.329527\n",
      "[26]\tvalid_0's gini: 0.334375\n",
      "[27]\tvalid_0's gini: 0.336005\n",
      "[28]\tvalid_0's gini: 0.337194\n",
      "[29]\tvalid_0's gini: 0.338785\n",
      "[30]\tvalid_0's gini: 0.340888\n",
      "[31]\tvalid_0's gini: 0.342322\n",
      "[32]\tvalid_0's gini: 0.344108\n",
      "[33]\tvalid_0's gini: 0.351327\n",
      "[34]\tvalid_0's gini: 0.353434\n",
      "[35]\tvalid_0's gini: 0.353788\n",
      "[36]\tvalid_0's gini: 0.354213\n",
      "[37]\tvalid_0's gini: 0.357496\n",
      "[38]\tvalid_0's gini: 0.359195\n",
      "[39]\tvalid_0's gini: 0.360486\n",
      "[40]\tvalid_0's gini: 0.361577\n",
      "[41]\tvalid_0's gini: 0.36215\n",
      "[42]\tvalid_0's gini: 0.364092\n",
      "[43]\tvalid_0's gini: 0.364645\n",
      "[44]\tvalid_0's gini: 0.365237\n",
      "[45]\tvalid_0's gini: 0.366586\n",
      "[46]\tvalid_0's gini: 0.367982\n",
      "[47]\tvalid_0's gini: 0.36929\n",
      "[48]\tvalid_0's gini: 0.369606\n",
      "[49]\tvalid_0's gini: 0.370986\n",
      "[50]\tvalid_0's gini: 0.371522\n",
      "[51]\tvalid_0's gini: 0.371657\n",
      "[52]\tvalid_0's gini: 0.372545\n",
      "[53]\tvalid_0's gini: 0.373097\n",
      "[54]\tvalid_0's gini: 0.373997\n",
      "[55]\tvalid_0's gini: 0.374684\n",
      "[56]\tvalid_0's gini: 0.37634\n",
      "[57]\tvalid_0's gini: 0.375966\n",
      "[58]\tvalid_0's gini: 0.376028\n",
      "[59]\tvalid_0's gini: 0.377119\n",
      "[60]\tvalid_0's gini: 0.378661\n",
      "[61]\tvalid_0's gini: 0.378828\n",
      "[62]\tvalid_0's gini: 0.379676\n",
      "[63]\tvalid_0's gini: 0.37963\n",
      "[64]\tvalid_0's gini: 0.379551\n",
      "[65]\tvalid_0's gini: 0.380671\n",
      "[66]\tvalid_0's gini: 0.380365\n",
      "[67]\tvalid_0's gini: 0.379761\n",
      "[68]\tvalid_0's gini: 0.380046\n",
      "[69]\tvalid_0's gini: 0.379748\n",
      "[70]\tvalid_0's gini: 0.379933\n",
      "[71]\tvalid_0's gini: 0.381177\n",
      "[72]\tvalid_0's gini: 0.381479\n",
      "[73]\tvalid_0's gini: 0.382663\n",
      "[74]\tvalid_0's gini: 0.382671\n",
      "[75]\tvalid_0's gini: 0.381967\n",
      "[76]\tvalid_0's gini: 0.381751\n",
      "[77]\tvalid_0's gini: 0.381832\n",
      "[78]\tvalid_0's gini: 0.381555\n",
      "[79]\tvalid_0's gini: 0.381407\n",
      "[80]\tvalid_0's gini: 0.381351\n",
      "[81]\tvalid_0's gini: 0.38196\n",
      "[82]\tvalid_0's gini: 0.381661\n",
      "[83]\tvalid_0's gini: 0.382576\n",
      "[84]\tvalid_0's gini: 0.382528\n",
      "[85]\tvalid_0's gini: 0.382686\n",
      "[86]\tvalid_0's gini: 0.382504\n",
      "[87]\tvalid_0's gini: 0.383247\n",
      "[88]\tvalid_0's gini: 0.382736\n",
      "[89]\tvalid_0's gini: 0.382309\n",
      "[90]\tvalid_0's gini: 0.381954\n",
      "[91]\tvalid_0's gini: 0.381412\n",
      "[92]\tvalid_0's gini: 0.382971\n",
      "[93]\tvalid_0's gini: 0.382869\n",
      "[94]\tvalid_0's gini: 0.383023\n",
      "[95]\tvalid_0's gini: 0.382939\n",
      "[96]\tvalid_0's gini: 0.383214\n",
      "[97]\tvalid_0's gini: 0.383409\n",
      "[98]\tvalid_0's gini: 0.382808\n",
      "[99]\tvalid_0's gini: 0.382594\n",
      "[100]\tvalid_0's gini: 0.381648\n",
      "[101]\tvalid_0's gini: 0.381481\n",
      "[102]\tvalid_0's gini: 0.381422\n",
      "[103]\tvalid_0's gini: 0.38131\n",
      "[104]\tvalid_0's gini: 0.380648\n",
      "[105]\tvalid_0's gini: 0.380189\n",
      "[106]\tvalid_0's gini: 0.380202\n",
      "[107]\tvalid_0's gini: 0.380241\n",
      "[108]\tvalid_0's gini: 0.380307\n",
      "[109]\tvalid_0's gini: 0.380474\n",
      "[110]\tvalid_0's gini: 0.381108\n",
      "[111]\tvalid_0's gini: 0.381176\n",
      "[112]\tvalid_0's gini: 0.380871\n",
      "[113]\tvalid_0's gini: 0.380741\n",
      "[114]\tvalid_0's gini: 0.381014\n",
      "[115]\tvalid_0's gini: 0.381198\n",
      "[116]\tvalid_0's gini: 0.381047\n",
      "[117]\tvalid_0's gini: 0.381497\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's gini: 0.383409\n",
      "Fold  3 : 0.383409 @ 200 \n",
      "[1]\tvalid_0's gini: 0.231906\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\tvalid_0's gini: 0.253211\n",
      "[3]\tvalid_0's gini: 0.261129\n",
      "[4]\tvalid_0's gini: 0.26174\n",
      "[5]\tvalid_0's gini: 0.270194\n",
      "[6]\tvalid_0's gini: 0.27617\n",
      "[7]\tvalid_0's gini: 0.281245\n",
      "[8]\tvalid_0's gini: 0.289988\n",
      "[9]\tvalid_0's gini: 0.290794\n",
      "[10]\tvalid_0's gini: 0.298183\n",
      "[11]\tvalid_0's gini: 0.302103\n",
      "[12]\tvalid_0's gini: 0.304509\n",
      "[13]\tvalid_0's gini: 0.305893\n",
      "[14]\tvalid_0's gini: 0.306047\n",
      "[15]\tvalid_0's gini: 0.308548\n",
      "[16]\tvalid_0's gini: 0.308779\n",
      "[17]\tvalid_0's gini: 0.309864\n",
      "[18]\tvalid_0's gini: 0.310539\n",
      "[19]\tvalid_0's gini: 0.310777\n",
      "[20]\tvalid_0's gini: 0.313619\n",
      "[21]\tvalid_0's gini: 0.31529\n",
      "[22]\tvalid_0's gini: 0.315662\n",
      "[23]\tvalid_0's gini: 0.317392\n",
      "[24]\tvalid_0's gini: 0.318652\n",
      "[25]\tvalid_0's gini: 0.318139\n",
      "[26]\tvalid_0's gini: 0.320174\n",
      "[27]\tvalid_0's gini: 0.321058\n",
      "[28]\tvalid_0's gini: 0.322211\n",
      "[29]\tvalid_0's gini: 0.323179\n",
      "[30]\tvalid_0's gini: 0.32462\n",
      "[31]\tvalid_0's gini: 0.328733\n",
      "[32]\tvalid_0's gini: 0.331079\n",
      "[33]\tvalid_0's gini: 0.33357\n",
      "[34]\tvalid_0's gini: 0.336289\n",
      "[35]\tvalid_0's gini: 0.339156\n",
      "[36]\tvalid_0's gini: 0.341234\n",
      "[37]\tvalid_0's gini: 0.34358\n",
      "[38]\tvalid_0's gini: 0.346293\n",
      "[39]\tvalid_0's gini: 0.349756\n",
      "[40]\tvalid_0's gini: 0.350267\n",
      "[41]\tvalid_0's gini: 0.351146\n",
      "[42]\tvalid_0's gini: 0.351848\n",
      "[43]\tvalid_0's gini: 0.355797\n",
      "[44]\tvalid_0's gini: 0.358904\n",
      "[45]\tvalid_0's gini: 0.360304\n",
      "[46]\tvalid_0's gini: 0.361823\n",
      "[47]\tvalid_0's gini: 0.36376\n",
      "[48]\tvalid_0's gini: 0.364191\n",
      "[49]\tvalid_0's gini: 0.364831\n",
      "[50]\tvalid_0's gini: 0.367367\n",
      "[51]\tvalid_0's gini: 0.370656\n",
      "[52]\tvalid_0's gini: 0.372582\n",
      "[53]\tvalid_0's gini: 0.372219\n",
      "[54]\tvalid_0's gini: 0.373072\n",
      "[55]\tvalid_0's gini: 0.37369\n",
      "[56]\tvalid_0's gini: 0.374378\n",
      "[57]\tvalid_0's gini: 0.375213\n",
      "[58]\tvalid_0's gini: 0.375803\n",
      "[59]\tvalid_0's gini: 0.376877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60]\tvalid_0's gini: 0.377112\n",
      "[61]\tvalid_0's gini: 0.377225\n",
      "[62]\tvalid_0's gini: 0.377401\n",
      "[63]\tvalid_0's gini: 0.377204\n",
      "[64]\tvalid_0's gini: 0.378034\n",
      "[65]\tvalid_0's gini: 0.378526\n",
      "[66]\tvalid_0's gini: 0.379038\n",
      "[67]\tvalid_0's gini: 0.379868\n",
      "[68]\tvalid_0's gini: 0.380133\n",
      "[69]\tvalid_0's gini: 0.380391\n",
      "[70]\tvalid_0's gini: 0.380566\n",
      "[71]\tvalid_0's gini: 0.380492\n",
      "[72]\tvalid_0's gini: 0.381269\n",
      "[73]\tvalid_0's gini: 0.381375\n",
      "[74]\tvalid_0's gini: 0.38168\n",
      "[75]\tvalid_0's gini: 0.382439\n",
      "[76]\tvalid_0's gini: 0.382306\n",
      "[77]\tvalid_0's gini: 0.383682\n",
      "[78]\tvalid_0's gini: 0.383992\n",
      "[79]\tvalid_0's gini: 0.384187\n",
      "[80]\tvalid_0's gini: 0.38451\n",
      "[81]\tvalid_0's gini: 0.384942\n",
      "[82]\tvalid_0's gini: 0.3849\n",
      "[83]\tvalid_0's gini: 0.385059\n",
      "[84]\tvalid_0's gini: 0.38576\n",
      "[85]\tvalid_0's gini: 0.385472\n",
      "[86]\tvalid_0's gini: 0.385906\n",
      "[87]\tvalid_0's gini: 0.385988\n",
      "[88]\tvalid_0's gini: 0.386675\n",
      "[89]\tvalid_0's gini: 0.387824\n",
      "[90]\tvalid_0's gini: 0.388693\n",
      "[91]\tvalid_0's gini: 0.389017\n",
      "[92]\tvalid_0's gini: 0.388846\n",
      "[93]\tvalid_0's gini: 0.388733\n",
      "[94]\tvalid_0's gini: 0.389578\n",
      "[95]\tvalid_0's gini: 0.389778\n",
      "[96]\tvalid_0's gini: 0.389716\n",
      "[97]\tvalid_0's gini: 0.389774\n",
      "[98]\tvalid_0's gini: 0.389911\n",
      "[99]\tvalid_0's gini: 0.389957\n",
      "[100]\tvalid_0's gini: 0.390003\n",
      "[101]\tvalid_0's gini: 0.391015\n",
      "[102]\tvalid_0's gini: 0.393086\n",
      "[103]\tvalid_0's gini: 0.39299\n",
      "[104]\tvalid_0's gini: 0.393076\n",
      "[105]\tvalid_0's gini: 0.392892\n",
      "[106]\tvalid_0's gini: 0.392735\n",
      "[107]\tvalid_0's gini: 0.392742\n",
      "[108]\tvalid_0's gini: 0.39302\n",
      "[109]\tvalid_0's gini: 0.393457\n",
      "[110]\tvalid_0's gini: 0.394152\n",
      "[111]\tvalid_0's gini: 0.394443\n",
      "[112]\tvalid_0's gini: 0.394398\n",
      "[113]\tvalid_0's gini: 0.394177\n",
      "[114]\tvalid_0's gini: 0.393818\n",
      "[115]\tvalid_0's gini: 0.39349\n",
      "[116]\tvalid_0's gini: 0.393232\n",
      "[117]\tvalid_0's gini: 0.393456\n",
      "[118]\tvalid_0's gini: 0.393965\n",
      "[119]\tvalid_0's gini: 0.393815\n",
      "[120]\tvalid_0's gini: 0.393887\n",
      "[121]\tvalid_0's gini: 0.394212\n",
      "[122]\tvalid_0's gini: 0.394646\n",
      "[123]\tvalid_0's gini: 0.394621\n",
      "[124]\tvalid_0's gini: 0.394567\n",
      "[125]\tvalid_0's gini: 0.394648\n",
      "[126]\tvalid_0's gini: 0.394379\n",
      "[127]\tvalid_0's gini: 0.394524\n",
      "[128]\tvalid_0's gini: 0.394347\n",
      "[129]\tvalid_0's gini: 0.393874\n",
      "[130]\tvalid_0's gini: 0.393811\n",
      "[131]\tvalid_0's gini: 0.394172\n",
      "[132]\tvalid_0's gini: 0.394752\n",
      "[133]\tvalid_0's gini: 0.394337\n",
      "[134]\tvalid_0's gini: 0.394235\n",
      "[135]\tvalid_0's gini: 0.394813\n",
      "[136]\tvalid_0's gini: 0.395158\n",
      "[137]\tvalid_0's gini: 0.395187\n",
      "[138]\tvalid_0's gini: 0.395429\n",
      "[139]\tvalid_0's gini: 0.395086\n",
      "[140]\tvalid_0's gini: 0.395803\n",
      "[141]\tvalid_0's gini: 0.395894\n",
      "[142]\tvalid_0's gini: 0.39531\n",
      "[143]\tvalid_0's gini: 0.395434\n",
      "[144]\tvalid_0's gini: 0.395777\n",
      "[145]\tvalid_0's gini: 0.395846\n",
      "[146]\tvalid_0's gini: 0.396404\n",
      "[147]\tvalid_0's gini: 0.396335\n",
      "[148]\tvalid_0's gini: 0.396637\n",
      "[149]\tvalid_0's gini: 0.396196\n",
      "[150]\tvalid_0's gini: 0.396551\n",
      "[151]\tvalid_0's gini: 0.396671\n",
      "[152]\tvalid_0's gini: 0.397131\n",
      "[153]\tvalid_0's gini: 0.397106\n",
      "[154]\tvalid_0's gini: 0.396723\n",
      "[155]\tvalid_0's gini: 0.396484\n",
      "[156]\tvalid_0's gini: 0.396828\n",
      "[157]\tvalid_0's gini: 0.396802\n",
      "[158]\tvalid_0's gini: 0.396378\n",
      "[159]\tvalid_0's gini: 0.396244\n",
      "[160]\tvalid_0's gini: 0.396219\n",
      "[161]\tvalid_0's gini: 0.395765\n",
      "[162]\tvalid_0's gini: 0.395564\n",
      "[163]\tvalid_0's gini: 0.395246\n",
      "[164]\tvalid_0's gini: 0.394876\n",
      "[165]\tvalid_0's gini: 0.394576\n",
      "[166]\tvalid_0's gini: 0.39454\n",
      "[167]\tvalid_0's gini: 0.394708\n",
      "[168]\tvalid_0's gini: 0.394608\n",
      "[169]\tvalid_0's gini: 0.395675\n",
      "[170]\tvalid_0's gini: 0.395575\n",
      "[171]\tvalid_0's gini: 0.395536\n",
      "[172]\tvalid_0's gini: 0.395482\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's gini: 0.397131\n",
      "Fold  4 : 0.397131 @ 200 \n",
      "[1]\tvalid_0's gini: 0.219522\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\tvalid_0's gini: 0.232725\n",
      "[3]\tvalid_0's gini: 0.242664\n",
      "[4]\tvalid_0's gini: 0.257291\n",
      "[5]\tvalid_0's gini: 0.263242\n",
      "[6]\tvalid_0's gini: 0.271284\n",
      "[7]\tvalid_0's gini: 0.271578\n",
      "[8]\tvalid_0's gini: 0.276147\n",
      "[9]\tvalid_0's gini: 0.27967\n",
      "[10]\tvalid_0's gini: 0.282506\n",
      "[11]\tvalid_0's gini: 0.286655\n",
      "[12]\tvalid_0's gini: 0.289949\n",
      "[13]\tvalid_0's gini: 0.294233\n",
      "[14]\tvalid_0's gini: 0.296006\n",
      "[15]\tvalid_0's gini: 0.299116\n",
      "[16]\tvalid_0's gini: 0.301501\n",
      "[17]\tvalid_0's gini: 0.304997\n",
      "[18]\tvalid_0's gini: 0.306991\n",
      "[19]\tvalid_0's gini: 0.307789\n",
      "[20]\tvalid_0's gini: 0.31125\n",
      "[21]\tvalid_0's gini: 0.313458\n",
      "[22]\tvalid_0's gini: 0.314023\n",
      "[23]\tvalid_0's gini: 0.314801\n",
      "[24]\tvalid_0's gini: 0.316219\n",
      "[25]\tvalid_0's gini: 0.319652\n",
      "[26]\tvalid_0's gini: 0.321856\n",
      "[27]\tvalid_0's gini: 0.324128\n",
      "[28]\tvalid_0's gini: 0.325422\n",
      "[29]\tvalid_0's gini: 0.330306\n",
      "[30]\tvalid_0's gini: 0.331685\n",
      "[31]\tvalid_0's gini: 0.332478\n",
      "[32]\tvalid_0's gini: 0.335456\n",
      "[33]\tvalid_0's gini: 0.337604\n",
      "[34]\tvalid_0's gini: 0.340856\n",
      "[35]\tvalid_0's gini: 0.341544\n",
      "[36]\tvalid_0's gini: 0.342754\n",
      "[37]\tvalid_0's gini: 0.344717\n",
      "[38]\tvalid_0's gini: 0.345829\n",
      "[39]\tvalid_0's gini: 0.34994\n",
      "[40]\tvalid_0's gini: 0.351051\n",
      "[41]\tvalid_0's gini: 0.352333\n",
      "[42]\tvalid_0's gini: 0.352525\n",
      "[43]\tvalid_0's gini: 0.353022\n",
      "[44]\tvalid_0's gini: 0.355246\n",
      "[45]\tvalid_0's gini: 0.3556\n",
      "[46]\tvalid_0's gini: 0.357523\n",
      "[47]\tvalid_0's gini: 0.359429\n",
      "[48]\tvalid_0's gini: 0.361471\n",
      "[49]\tvalid_0's gini: 0.361795\n",
      "[50]\tvalid_0's gini: 0.36363\n",
      "[51]\tvalid_0's gini: 0.365912\n",
      "[52]\tvalid_0's gini: 0.366828\n",
      "[53]\tvalid_0's gini: 0.369009\n",
      "[54]\tvalid_0's gini: 0.371749\n",
      "[55]\tvalid_0's gini: 0.373422\n",
      "[56]\tvalid_0's gini: 0.373851\n",
      "[57]\tvalid_0's gini: 0.373687\n",
      "[58]\tvalid_0's gini: 0.374758\n",
      "[59]\tvalid_0's gini: 0.374943\n",
      "[60]\tvalid_0's gini: 0.377179\n",
      "[61]\tvalid_0's gini: 0.379588\n",
      "[62]\tvalid_0's gini: 0.37967\n",
      "[63]\tvalid_0's gini: 0.379563\n",
      "[64]\tvalid_0's gini: 0.38041\n",
      "[65]\tvalid_0's gini: 0.380225\n",
      "[66]\tvalid_0's gini: 0.380685\n",
      "[67]\tvalid_0's gini: 0.380623\n",
      "[68]\tvalid_0's gini: 0.380428\n",
      "[69]\tvalid_0's gini: 0.381274\n",
      "[70]\tvalid_0's gini: 0.381752\n",
      "[71]\tvalid_0's gini: 0.381147\n",
      "[72]\tvalid_0's gini: 0.381917\n",
      "[73]\tvalid_0's gini: 0.382229\n",
      "[74]\tvalid_0's gini: 0.382045\n",
      "[75]\tvalid_0's gini: 0.381888\n",
      "[76]\tvalid_0's gini: 0.382433\n",
      "[77]\tvalid_0's gini: 0.382454\n",
      "[78]\tvalid_0's gini: 0.382359\n",
      "[79]\tvalid_0's gini: 0.383068\n",
      "[80]\tvalid_0's gini: 0.382657\n",
      "[81]\tvalid_0's gini: 0.382772\n",
      "[82]\tvalid_0's gini: 0.383599\n",
      "[83]\tvalid_0's gini: 0.383698\n",
      "[84]\tvalid_0's gini: 0.383897\n",
      "[85]\tvalid_0's gini: 0.383894\n",
      "[86]\tvalid_0's gini: 0.384008\n",
      "[87]\tvalid_0's gini: 0.384272\n",
      "[88]\tvalid_0's gini: 0.384446\n",
      "[89]\tvalid_0's gini: 0.384989\n",
      "[90]\tvalid_0's gini: 0.385196\n",
      "[91]\tvalid_0's gini: 0.38453\n",
      "[92]\tvalid_0's gini: 0.38464\n",
      "[93]\tvalid_0's gini: 0.385126\n",
      "[94]\tvalid_0's gini: 0.385178\n",
      "[95]\tvalid_0's gini: 0.386097\n",
      "[96]\tvalid_0's gini: 0.385557\n",
      "[97]\tvalid_0's gini: 0.386677\n",
      "[98]\tvalid_0's gini: 0.3866\n",
      "[99]\tvalid_0's gini: 0.387228\n",
      "[100]\tvalid_0's gini: 0.386984\n",
      "[101]\tvalid_0's gini: 0.387137\n",
      "[102]\tvalid_0's gini: 0.38753\n",
      "[103]\tvalid_0's gini: 0.388709\n",
      "[104]\tvalid_0's gini: 0.388671\n",
      "[105]\tvalid_0's gini: 0.389078\n",
      "[106]\tvalid_0's gini: 0.388238\n",
      "[107]\tvalid_0's gini: 0.388528\n",
      "[108]\tvalid_0's gini: 0.388211\n",
      "[109]\tvalid_0's gini: 0.388004\n",
      "[110]\tvalid_0's gini: 0.387949\n",
      "[111]\tvalid_0's gini: 0.38795\n",
      "[112]\tvalid_0's gini: 0.388056\n",
      "[113]\tvalid_0's gini: 0.388351\n",
      "[114]\tvalid_0's gini: 0.388912\n",
      "[115]\tvalid_0's gini: 0.389366\n",
      "[116]\tvalid_0's gini: 0.389627\n",
      "[117]\tvalid_0's gini: 0.390615\n",
      "[118]\tvalid_0's gini: 0.390292\n",
      "[119]\tvalid_0's gini: 0.390455\n",
      "[120]\tvalid_0's gini: 0.390642\n",
      "[121]\tvalid_0's gini: 0.390296\n",
      "[122]\tvalid_0's gini: 0.390924\n",
      "[123]\tvalid_0's gini: 0.390622\n",
      "[124]\tvalid_0's gini: 0.390331\n",
      "[125]\tvalid_0's gini: 0.391354\n",
      "[126]\tvalid_0's gini: 0.391369\n",
      "[127]\tvalid_0's gini: 0.391533\n",
      "[128]\tvalid_0's gini: 0.391161\n",
      "[129]\tvalid_0's gini: 0.391119\n",
      "[130]\tvalid_0's gini: 0.391196\n",
      "[131]\tvalid_0's gini: 0.391336\n",
      "[132]\tvalid_0's gini: 0.390711\n",
      "[133]\tvalid_0's gini: 0.390532\n",
      "[134]\tvalid_0's gini: 0.390762\n",
      "[135]\tvalid_0's gini: 0.390583\n",
      "[136]\tvalid_0's gini: 0.391204\n",
      "[137]\tvalid_0's gini: 0.390959\n",
      "[138]\tvalid_0's gini: 0.390957\n",
      "[139]\tvalid_0's gini: 0.391447\n",
      "[140]\tvalid_0's gini: 0.391951\n",
      "[141]\tvalid_0's gini: 0.392362\n",
      "[142]\tvalid_0's gini: 0.392124\n",
      "[143]\tvalid_0's gini: 0.391875\n",
      "[144]\tvalid_0's gini: 0.392711\n",
      "[145]\tvalid_0's gini: 0.393049\n",
      "[146]\tvalid_0's gini: 0.392517\n",
      "[147]\tvalid_0's gini: 0.39231\n",
      "[148]\tvalid_0's gini: 0.393471\n",
      "[149]\tvalid_0's gini: 0.393205\n",
      "[150]\tvalid_0's gini: 0.39279\n",
      "[151]\tvalid_0's gini: 0.392864\n",
      "[152]\tvalid_0's gini: 0.393167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153]\tvalid_0's gini: 0.393361\n",
      "[154]\tvalid_0's gini: 0.394741\n",
      "[155]\tvalid_0's gini: 0.395174\n",
      "[156]\tvalid_0's gini: 0.395572\n",
      "[157]\tvalid_0's gini: 0.395775\n",
      "[158]\tvalid_0's gini: 0.395733\n",
      "[159]\tvalid_0's gini: 0.395524\n",
      "[160]\tvalid_0's gini: 0.396211\n",
      "[161]\tvalid_0's gini: 0.396222\n",
      "[162]\tvalid_0's gini: 0.396403\n",
      "[163]\tvalid_0's gini: 0.396184\n",
      "[164]\tvalid_0's gini: 0.396178\n",
      "[165]\tvalid_0's gini: 0.396389\n",
      "[166]\tvalid_0's gini: 0.396414\n",
      "[167]\tvalid_0's gini: 0.396915\n",
      "[168]\tvalid_0's gini: 0.397136\n",
      "[169]\tvalid_0's gini: 0.396524\n",
      "[170]\tvalid_0's gini: 0.396591\n",
      "[171]\tvalid_0's gini: 0.396083\n",
      "[172]\tvalid_0's gini: 0.395928\n",
      "[173]\tvalid_0's gini: 0.395868\n",
      "[174]\tvalid_0's gini: 0.396106\n",
      "[175]\tvalid_0's gini: 0.395972\n",
      "[176]\tvalid_0's gini: 0.396275\n",
      "[177]\tvalid_0's gini: 0.395772\n",
      "[178]\tvalid_0's gini: 0.395604\n",
      "[179]\tvalid_0's gini: 0.395409\n",
      "[180]\tvalid_0's gini: 0.395739\n",
      "[181]\tvalid_0's gini: 0.39581\n",
      "[182]\tvalid_0's gini: 0.396072\n",
      "[183]\tvalid_0's gini: 0.397198\n",
      "[184]\tvalid_0's gini: 0.398061\n",
      "[185]\tvalid_0's gini: 0.39805\n",
      "[186]\tvalid_0's gini: 0.397563\n",
      "[187]\tvalid_0's gini: 0.397248\n",
      "[188]\tvalid_0's gini: 0.397059\n",
      "[189]\tvalid_0's gini: 0.396816\n",
      "[190]\tvalid_0's gini: 0.39771\n",
      "[191]\tvalid_0's gini: 0.39754\n",
      "[192]\tvalid_0's gini: 0.398964\n",
      "[193]\tvalid_0's gini: 0.398508\n",
      "[194]\tvalid_0's gini: 0.398676\n",
      "[195]\tvalid_0's gini: 0.40023\n",
      "[196]\tvalid_0's gini: 0.400122\n",
      "[197]\tvalid_0's gini: 0.400529\n",
      "[198]\tvalid_0's gini: 0.400675\n",
      "[199]\tvalid_0's gini: 0.401344\n",
      "[200]\tvalid_0's gini: 0.40176\n",
      "Fold  5 : 0.401760 @ 200 \n"
     ]
    }
   ],
   "source": [
    "for fold_ in range(len(idx_info)):\n",
    "    l = idx_info[fold_]\n",
    "    trn_idx = l[0]\n",
    "    val_idx = l[1]\n",
    "    trn_dat, trn_tgt = trn_df.iloc[trn_idx], tgt.iloc[trn_idx]\n",
    "    val_dat, val_tgt = trn_df.iloc[val_idx], tgt.iloc[val_idx]\n",
    "    \n",
    "    pos = sum(trn_tgt==0)/sum(trn_tgt==1)\n",
    "    wts = np.array([pos if x==1 else 1 for x in trn_tgt])\n",
    "    \n",
    "    eval_pos = sum(val_tgt==0)/sum(val_tgt==1)\n",
    "    eval_wts = [eval_pos if x==1 else 1 for x in val_tgt]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(trn_dat, trn_tgt,\n",
    "                        weight=wts, free_raw_data=False)\n",
    "    lgb_eval = lgb.Dataset(val_dat, val_tgt, reference=lgb_train,\n",
    "                       weight=eval_wts, free_raw_data=False)\n",
    "\n",
    "#     clf = LGBMClassifier(objective='binary:logistic', sample_weight=wts, num_leaves=150, n_estimators=400, \n",
    "#                          learning_rate=0.05, max_bin=400, max_depth=10)\n",
    "#     clf.fit(trn_dat, trn_tgt, sample_weight=wts, \n",
    "#             eval_set=[(trn_dat, trn_tgt), (val_dat, val_tgt)],\n",
    "#             #eval_sample_weight = eval_wts,\n",
    "#             eval_metric=gini_xgb,\n",
    "#             early_stopping_rounds=None,\n",
    "#             verbose=True)\n",
    "    \n",
    "    clf = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=200,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    feval = gini_lgbm,\n",
    "                    early_stopping_rounds=20)\n",
    "    \n",
    "    # Predict OOF and submission probas with the best round\n",
    "    oof_lgbm[val_idx] = clf.predict(val_dat, num_iteration=clf.best_iteration)\n",
    "    # Update submission\n",
    "    \n",
    "    sub_preds += clf.predict(sub_df, num_iteration=clf.best_iteration) / n_splits\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Fold %2d : %.6f @%4d \"\n",
    "          % (fold_ + 1,\n",
    "             eval_gini(val_tgt, oof_lgbm[val_idx]),\n",
    "             n_estimators\n",
    "             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../cache/oof_lgbm', oof_lgbm)\n",
    "now = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "fn = '../cache/model.lgbm.{}'.format(now)\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_preds = np.clip(sub_preds, a_min=0.05, a_max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../cache/test_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sub_df[\"target\"] = sub_preds\n",
    "sub_df['id'] = df['id'].values\n",
    "now = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "fn = '../submissions/sub.lgbm.{}'.format(now)\n",
    "sub_df[['id', \"target\"]].to_csv(fn, index=False, float_format=\"%.9f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdp35",
   "language": "python",
   "name": "sdp35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
